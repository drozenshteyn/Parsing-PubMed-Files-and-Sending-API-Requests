{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e5311c8-e6bb-4047-8abf-8ab6dae96571",
   "metadata": {},
   "source": [
    "# How to Parse PubMed Search Text Files Using Data Element Field #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a362c5f4-2c61-4515-ad17-43343fc3480f",
   "metadata": {},
   "source": [
    "This article follows up on a piece I published a few months ago about building a dataset of PubMed-listed publications on cardiovascular disease research. \n",
    "\n",
    "Please read the original article for the background context before proceeding: https://medium.com/towards-data-science/building-a-pubmed-dataset-b1267408417c "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b65ce66-1d16-4859-a800-c52aa44f8b76",
   "metadata": {},
   "source": [
    "The original dataset of PubMed-listed publications on cardiovascular disease research, created for my Master’s Thesis titled \"Factors Associated with Impactful Scientific Publications in NIH-Funded Heart Disease Research,\" required details such as the journal name, the first author's institutional affiliation, and their country. To preserve this information for further parsing, I saved the advanced search PubMed queries[1] by selecting the abstract format in the display options and choosing the PubMed format in the \"Save Citations\" menu. This will create a file in the text format.\n",
    "\n",
    "The flowchart below outlines the steps to parse the information described above from the PubMed format file. A detailed explanation follows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a451d5-c04f-4af0-b0d9-e2cf8f791e4d",
   "metadata": {},
   "source": [
    "![Parsing_API_1](Parsing_API_1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cad7db2-b7c7-4741-bf32-3679b67953c8",
   "metadata": {},
   "source": [
    "Since the PubMed format dataset cannot be saved in a CSV format and easily be formatted into a table, it has to be parsed to extract Journal Title (JT), first Author Institution Affiliation (AD), and country. \n",
    "\n",
    "Bellow is the example of the single PubMed format file entry. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57e1562-4cf4-4f50-b459-0109370e940d",
   "metadata": {},
   "source": [
    "![PubMed_dataset_4](PubMed_dataset_4.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9271913b-3b14-45fb-be00-3163815fb50f",
   "metadata": {},
   "source": [
    "I developed a parsing script using Python 3.10.1 for this purpose.  First author affiliation was determined by making an Application Programming Interface (API) request to the Research Organization Registry (ROR) API [2]. ROR matching was necessary because Data Element field provided inconsistent names for the research institutions along with unnecessary information such as address and department name. ROR affiliation matching allows to find research organizations mentioned in the full affiliation strings from the PubMed format datasets which are then provided in the API call. The results of the API call are returned in the JSON format. I parsed journal titles and countries from the PubMed format datasets using PubMed Data Element (Field) Descriptions included in this type of file format. Once the script is executed, the output file will be in a single-line format with parsed data separated by a vertical line (`|`). This format allows for easy conversion from a one-line text file to a table in CSV format within a Jupyter Lab notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f27e292a-2979-4f30-83cc-06d5caacda68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport requests\\nimport urllib.parse\\nimport json\\n\\n# writing to file\\noutfile = open(\\'Heart_NHLBI_2020_oneline.txt\\', \\'w\\', encoding=\"utf-8\")\\n \\n# Using readlines()\\ninfile = open(\\'Heart_disease_publications_NHLBI_2020.txt\\', \\'r\\', encoding=\"utf-8\")\\ninstitution_info = \\'\\'\\npmid = \\'\\'\\njournal = \\'\\'\\n\\ndef determine_ror_id(institution_info):\\n    response =  None\\n    try:\\n        response = requests.get(\\'https://api.ror.org/organizations?affiliation=\\' + urllib.parse.quote(institution_info)).json()\\n        number_of_results = response[\\'number_of_results\\']\\n        if number_of_results > 0:\\n            institution_name = response[\\'items\\'][0][\\'organization\\'][\\'name\\']\\n            country = response[\\'items\\'][0][\\'organization\\'][\\'country\\'][\\'country_name\\']        \\n        else:\\n            institution_name = \\'not found\\'\\n            country = \\'not found\\'\\n            print(institution_info, response)\\n    except:\\n        institution_name = \\'not found\\'\\n        country = \\'not found\\'\\n        print(institution_info)\\n        print(response)\\n    return (institution_name, country)\\n\\n    #data = ror_id[\\'number_of_results\\'][\\'items\\'][\\'substring\\']\\n     #       for x in data:\\n\\t  #          print(x[\\'substring\\'])   \\n\\n# Strips the newline character\\nwhile True:\\n    # Get next line from file\\n    line = infile.readline()\\n    # if line is empty\\n    # end of file is reached\\n    if not line:\\n        break\\n    if line.startswith(\\'PMID\\'):\\n\\n        if institution_info:\\n            institution_name, country = determine_ror_id(institution_info.strip())\\n            \\n            outfile.write(pmid.strip() + \\'|\\' + institution_info.strip() + \\'|\\' + institution_name + \\'|\\' + country + \\'|\\' + journal.strip() + \\'\\n\\')\\n            institution_info = \\'\\'\\n            institution_name = \\'\\'\\n            country = \\'\\'\\n            \\n        line_tokens = line.split(\\'- \\')\\n        pmid = line_tokens[1].strip()\\n\\n    if line.startswith(\\'AD\\'):\\n        if not institution_info:\\n            line = line.replace(\\'|\\',\\' \\')\\n            line_tokens = line.split(\\'- \\')\\n            institution_info = line_tokens[1].strip()\\n            line = infile.readline()\\n            while line and line.startswith(\\' \\'):\\n                line = line.replace(\\'|\\',\\' \\')\\n                institution_info = institution_info + \\' \\' + line.strip()\\n                line = infile.readline()\\n\\n    if line.startswith(\\'JT\\'):       \\n        line_tokens = line.split(\\'- \\')\\n        journal = line_tokens[1].strip().lower()\\n        if journal.startswith(\\'the\\'):\\n            sep = \\'the\\'\\n            journal = journal.split(sep, 1)[1]\\n        if \\'(\\' in journal:\\n            sep = \\'(\\'\\n            journal = journal.split(sep, 1)[0]\\n        elif \\' :\\' in journal:\\n            sep = \\' :\\'\\n            journal = journal.split(sep, 1)[0]\\n\\n        line = infile.readline()\\n                \\ninfile.close()\\noutfile.close()\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import requests\n",
    "import urllib.parse\n",
    "import json\n",
    "\n",
    "# writing to file\n",
    "outfile = open('Heart_NHLBI_2002_oneline.txt', 'w', encoding=\"utf-8\")\n",
    " \n",
    "# Using readlines()\n",
    "infile = open('Heart_disease_publications_NHLBI_2002.txt', 'r', encoding=\"utf-8\")\n",
    "institution_info = ''\n",
    "pmid = ''\n",
    "journal = ''\n",
    "\n",
    "def determine_ror_id(institution_info):\n",
    "    response =  None\n",
    "    try:\n",
    "        response = requests.get('https://api.ror.org/organizations?affiliation=' + urllib.parse.quote(institution_info)).json()\n",
    "        number_of_results = response['number_of_results']\n",
    "        if number_of_results > 0:\n",
    "            institution_name = response['items'][0]['organization']['name']\n",
    "            country = response['items'][0]['organization']['country']['country_name']        \n",
    "        else:\n",
    "            institution_name = 'not found'\n",
    "            country = 'not found'\n",
    "            print(institution_info, response)\n",
    "    except:\n",
    "        institution_name = 'not found'\n",
    "        country = 'not found'\n",
    "        print(institution_info)\n",
    "        print(response)\n",
    "    return (institution_name, country)\n",
    "\n",
    "# Strips the newline character\n",
    "while True:\n",
    "    # Get next line from file\n",
    "    line = infile.readline()\n",
    "    # if line is empty\n",
    "    # end of file is reached\n",
    "    if not line:\n",
    "        break\n",
    "    if line.startswith('PMID'):\n",
    "\n",
    "        if institution_info:\n",
    "            institution_name, country = determine_ror_id(institution_info.strip())\n",
    "            \n",
    "            outfile.write(pmid.strip() + '|' + institution_info.strip() + '|' + institution_name + '|' + country + '|' + journal.strip() + '\\n')\n",
    "            institution_info = ''\n",
    "            institution_name = ''\n",
    "            country = ''\n",
    "            \n",
    "        line_tokens = line.split('- ')\n",
    "        pmid = line_tokens[1].strip()\n",
    "\n",
    "    if line.startswith('AD'):\n",
    "        if not institution_info:\n",
    "            line = line.replace('|',' ')\n",
    "            line_tokens = line.split('- ')\n",
    "            institution_info = line_tokens[1].strip()\n",
    "            line = infile.readline()\n",
    "            while line and line.startswith(' '):\n",
    "                line = line.replace('|',' ')\n",
    "                institution_info = institution_info + ' ' + line.strip()\n",
    "                line = infile.readline()\n",
    "\n",
    "    if line.startswith('JT'):       \n",
    "        line_tokens = line.split('- ')\n",
    "        journal = line_tokens[1].strip().lower()\n",
    "        if journal.startswith('the'):\n",
    "            sep = 'the'\n",
    "            journal = journal.split(sep, 1)[1]\n",
    "        if '(' in journal:\n",
    "            sep = '('\n",
    "            journal = journal.split(sep, 1)[0]\n",
    "        elif ' :' in journal:\n",
    "            sep = ' :'\n",
    "            journal = journal.split(sep, 1)[0]\n",
    "\n",
    "        line = infile.readline()\n",
    "                \n",
    "infile.close()\n",
    "outfile.close()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c64cdd-4fa9-40a5-aeab-bc55f8857a4b",
   "metadata": {},
   "source": [
    "The Jupyter Notebook used for this article, along with the parsing script, a sample file to run the script, and an example of the expected output file, can be found on [GitHub](https://github.com/drozenshteyn/Parsing-PubMed-Files-and-Sending-API-Requests)\n",
    "\n",
    "The full MS Thesis referenced here can also be found on [GitHub](https://github.com/drozenshteyn/Master-s-Thesis)\n",
    "\n",
    "Note: I used GitHub embeds to publish this article.\n",
    "\n",
    "Thank you for reading,\n",
    "\n",
    "Diana"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e80b4e5-100c-451c-b3ab-d49c9b26223b",
   "metadata": {},
   "source": [
    "## References ##\n",
    "\n",
    "1. U.S. National Library of Medicine, “Advanced search results - pubmed,”. Available: https://pubmed.ncbi.nlm.nih.gov/advanced/\n",
    "2. Research Organization Registry, “ROR,” ror.org. Available: https://ror.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a65e59-3376-4054-9323-03a80614742d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
